"""
FSC-RAG æŸ¥è©¢ä»‹é¢

é‡‘ç®¡æœƒæ–‡ä»¶ RAG ç³»çµ± - Streamlit å‰ç«¯
"""
import os
import streamlit as st
from dotenv import load_dotenv

# è¼‰å…¥ç’°å¢ƒè®Šæ•¸
load_dotenv()

# é é¢è¨­å®š
st.set_page_config(
    page_title="é‡‘ç®¡æœƒæ–‡ä»¶æ™ºæ…§æŸ¥è©¢",
    page_icon="ğŸ›ï¸",
    layout="wide",
)

# æ¨™é¡Œ
st.title("ğŸ›ï¸ é‡‘ç®¡æœƒæ–‡ä»¶æ™ºæ…§æŸ¥è©¢")
st.markdown("ä½¿ç”¨ BGE-M3 + Qdrant + Gemini çš„ RAG ç³»çµ±")

# å´é‚Šæ¬„è¨­å®š
with st.sidebar:
    st.header("âš™ï¸ è¨­å®š")

    # è³‡æ–™é¡å‹ç¯©é¸
    st.subheader("è³‡æ–™é¡å‹")
    filter_penalty = st.checkbox("è£ç½°æ¡ˆä»¶", value=True)
    filter_law = st.checkbox("æ³•ä»¤å‡½é‡‹", value=True)
    filter_announcement = st.checkbox("é‡è¦å…¬å‘Š", value=True)

    # æœå°‹åƒæ•¸
    st.subheader("æœå°‹åƒæ•¸")
    top_k = st.slider("æœå°‹çµæœæ•¸é‡", min_value=1, max_value=20, value=5)

    # é¡¯ç¤ºæ¨¡å¼
    st.subheader("é¡¯ç¤ºæ¨¡å¼")
    show_sources = st.checkbox("é¡¯ç¤ºåƒè€ƒä¾†æº", value=True)

    st.markdown("---")
    st.markdown("**é—œæ–¼æœ¬ç³»çµ±**")
    st.markdown("""
    - Embedding: BGE-M3
    - å‘é‡è³‡æ–™åº«: Qdrant Cloud
    - LLM: Gemini 2.5 Flash
    """)


@st.cache_resource
def get_retriever():
    """åˆå§‹åŒ–æª¢ç´¢å™¨ï¼ˆå¿«å–ï¼‰"""
    from src.retriever.search import FSCRetriever
    return FSCRetriever(prefer_api=True, lazy_load=False)


@st.cache_resource
def get_llm():
    """åˆå§‹åŒ– Gemini LLMï¼ˆå¿«å–ï¼‰"""
    import google.generativeai as genai

    api_key = os.getenv("GEMINI_API_KEY")
    if not api_key:
        return None

    genai.configure(api_key=api_key)
    return genai.GenerativeModel("gemini-2.0-flash")


def generate_answer(llm, query: str, context: str) -> str:
    """ä½¿ç”¨ LLM ç”Ÿæˆå›ç­”"""
    prompt = f"""ä½ æ˜¯é‡‘èç›£ç£ç®¡ç†å§”å“¡æœƒçš„å°ˆæ¥­åŠ©ç†ï¼Œè«‹æ ¹æ“šä»¥ä¸‹åƒè€ƒè³‡æ–™å›ç­”å•é¡Œã€‚

å•é¡Œï¼š{query}

åƒè€ƒè³‡æ–™ï¼š
{context}

è«‹æ ¹æ“šåƒè€ƒè³‡æ–™æä¾›æº–ç¢ºã€å°ˆæ¥­çš„å›ç­”ã€‚å¦‚æœåƒè€ƒè³‡æ–™ä¸­æ²’æœ‰ç›¸é—œè³‡è¨Šï¼Œè«‹æ˜ç¢ºèªªæ˜ã€‚
å›ç­”æ™‚è«‹ï¼š
1. å¼•ç”¨å…·é«”çš„æ³•è¦æ¢æ–‡æˆ–è£ç½°æ¡ˆä¾‹
2. ä½¿ç”¨ç¹é«”ä¸­æ–‡
3. æ¢ç†æ¸…æ™°ï¼Œé‡é»çªå‡º
"""

    try:
        response = llm.generate_content(prompt)
        return response.text
    except Exception as e:
        return f"ç”Ÿæˆå›ç­”æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{str(e)}"


# ä¸»è¦æŸ¥è©¢å€åŸŸ
query = st.text_input(
    "ğŸ” è«‹è¼¸å…¥æ‚¨çš„å•é¡Œ",
    placeholder="ä¾‹å¦‚ï¼šä¿éšªå…¬å¸é•åæ´—éŒ¢é˜²åˆ¶è¦å®šæœƒå—åˆ°ä»€éº¼è™•ç½°ï¼Ÿ"
)

# æŸ¥è©¢æŒ‰éˆ•
if st.button("æœå°‹", type="primary") or (query and st.session_state.get("auto_search")):
    if not query:
        st.warning("è«‹è¼¸å…¥æŸ¥è©¢å•é¡Œ")
    else:
        # å»ºç«‹è³‡æ–™é¡å‹ç¯©é¸
        data_types = []
        if filter_penalty:
            data_types.append("penalty")
        if filter_law:
            data_types.append("law_interpretation")
        if filter_announcement:
            data_types.append("announcement")

        if not data_types:
            st.warning("è«‹è‡³å°‘é¸æ“‡ä¸€ç¨®è³‡æ–™é¡å‹")
        else:
            with st.spinner("æ­£åœ¨æœå°‹ç›¸é—œæ–‡ä»¶..."):
                try:
                    # åˆå§‹åŒ–å…ƒä»¶
                    retriever = get_retriever()
                    llm = get_llm()

                    # åŸ·è¡Œæœå°‹
                    results = retriever.search(
                        query=query,
                        top_k=top_k,
                        data_types=data_types if len(data_types) < 3 else None
                    )

                    if not results:
                        st.info("æœªæ‰¾åˆ°ç›¸é—œæ–‡ä»¶ï¼Œè«‹å˜—è©¦å…¶ä»–é—œéµå­—ã€‚")
                    else:
                        # ç”Ÿæˆä¸Šä¸‹æ–‡
                        context = retriever.get_context(
                            query=query,
                            top_k=top_k,
                            data_types=data_types if len(data_types) < 3 else None
                        )

                        # LLM å›ç­”
                        st.subheader("ğŸ’¡ AI å›ç­”")
                        if llm:
                            with st.spinner("æ­£åœ¨ç”Ÿæˆå›ç­”..."):
                                answer = generate_answer(llm, query, context)
                                st.markdown(answer)
                        else:
                            st.warning("æœªè¨­å®š GEMINI_API_KEYï¼Œç„¡æ³•ç”Ÿæˆ AI å›ç­”")

                        # é¡¯ç¤ºåƒè€ƒä¾†æº
                        if show_sources:
                            st.markdown("---")
                            st.subheader(f"ğŸ“š åƒè€ƒä¾†æº ({len(results)} ç­†)")

                            for i, r in enumerate(results, 1):
                                # è³‡æ–™é¡å‹æ¨™ç±¤
                                type_labels = {
                                    "penalty": "ğŸ”´ è£ç½°æ¡ˆä»¶",
                                    "law_interpretation": "ğŸ”µ æ³•ä»¤å‡½é‡‹",
                                    "announcement": "ğŸŸ¢ é‡è¦å…¬å‘Š"
                                }
                                type_label = type_labels.get(r.data_type, r.data_type)

                                with st.expander(
                                    f"{type_label} | ç›¸é—œåº¦: {r.score:.2%}",
                                    expanded=(i <= 2)
                                ):
                                    # å…ƒè³‡æ–™
                                    cols = st.columns(3)
                                    if r.metadata.get("date"):
                                        cols[0].markdown(f"**æ—¥æœŸ:** {r.metadata['date']}")
                                    if r.metadata.get("title"):
                                        cols[1].markdown(f"**æ¨™é¡Œ:** {r.metadata['title'][:30]}...")
                                    if r.metadata.get("doc_number"):
                                        cols[2].markdown(f"**æ–‡è™Ÿ:** {r.metadata['doc_number']}")

                                    # å…§å®¹
                                    st.markdown("**å…§å®¹:**")
                                    st.text(r.text[:500] + "..." if len(r.text) > 500 else r.text)

                                    st.caption(f"æ–‡ä»¶ ID: {r.doc_id} | Chunk ID: {r.chunk_id}")

                except Exception as e:
                    st.error(f"æœå°‹æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{str(e)}")
                    st.exception(e)

# ç¯„ä¾‹æŸ¥è©¢
st.markdown("---")
st.subheader("ğŸ’¡ ç¯„ä¾‹æŸ¥è©¢")

example_queries = [
    "ä¿éšªå…¬å¸é•åæ´—éŒ¢é˜²åˆ¶è¦å®šæœƒå—åˆ°ä»€éº¼è™•ç½°ï¼Ÿ",
    "è­‰åˆ¸äº¤æ˜“æ³•ç¬¬171æ¢çš„ç›¸é—œå‡½é‡‹æœ‰å“ªäº›ï¼Ÿ",
    "éŠ€è¡Œé•åå€‹è³‡æ³•çš„è£ç½°æ¡ˆä¾‹",
    "é‡‘èæ©Ÿæ§‹å…§éƒ¨æ§åˆ¶ç¼ºå¤±çš„è™•åˆ†æ¨™æº–",
]

cols = st.columns(2)
for i, eq in enumerate(example_queries):
    if cols[i % 2].button(eq, key=f"example_{i}"):
        st.session_state["auto_search"] = True
        st.rerun()
